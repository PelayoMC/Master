{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yarn --daemon start resourcemanager\n",
    "!yarn --daemon start proxyserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yarn --daemon start nodemanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir -p /media/notebooks/Modulo1/prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/media/notebooks/Modulo1/prueba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /dataset/texto.txt /media/notebooks/Modulo1/prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapper.py  reducer.py  salida  texto.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python3\n",
    "# coding=utf-8\n",
    "import sys\n",
    "\n",
    "#Leemos cada línea de la entrada estándar\n",
    "for line in sys.stdin:  \n",
    "  #Dividimos en palabras cada línea\n",
    "  words = line.split()  \n",
    "  #Iteramos sobre cada palabra contenida en words\n",
    "  for word in words:    \n",
    "  \t#Escribimos por salida estándar el par <Clave,Valor>\n",
    "\t#En este caso la Clave será la palabra en cuestión y el valor será 1\n",
    "\tprint '%s\\t%s' % (word,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python3\n",
    "# coding=utf-8\n",
    "import sys\n",
    "\t\n",
    "curr_word = None\n",
    "curr_count = 0\n",
    "\t\n",
    "# Procesamos cada Clave-Valor que produce la función map\n",
    "for line in sys.stdin:\n",
    "\t\n",
    "  #Dividimos la clave y el valor\n",
    "  word, count = line.split('\\t')\n",
    "\t\n",
    "  #Convertimos a entero el valor\n",
    "  count = int(count)\n",
    "\n",
    "  #Si la palabra actual es la misma que la previa, incrementamos el contador\n",
    "  #en otro caso imprimimos la palabra en cuestión con el contador\n",
    "  if word == curr_word:\n",
    "    curr_count += count\n",
    "  else:\n",
    "    if curr_word:   \n",
    "      print '%s\\t%s' % (curr_word, curr_count)\n",
    "\t\t\t\n",
    "    #Actualizamos las variables a la nueva palabra\n",
    "    curr_word = word\n",
    "    curr_count = count\n",
    "\t\n",
    "#Imprimimos la última palabra\n",
    "if curr_word == word:\n",
    "  print '%s\\t%s' % (curr_word, curr_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.0K\r\n",
      "-rw-r--r-- 1 root root 392 Nov 15 21:57 mapper.py\r\n",
      "-rw-r--r-- 1 root root 733 Nov 15 21:57 reducer.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /dataset/texto.txt | python mapper.py | sort | python reducer.py > salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esto\t2\r\n",
      "contador\t1\r\n",
      "de\t3\r\n",
      "ejemplo\t2\r\n",
      "es\t2\r\n",
      "mapreduce.\t1\r\n",
      "palabras.\t1\r\n",
      "programación\t1\r\n",
      "un\t2\r\n"
     ]
    }
   ],
   "source": [
    "!tail -60000 salida | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapper.py  reducer.py  salida  texto.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-15 22:46:45,414 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [./reducer.py, ./mapper.py] [/app/hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar] /tmp/streamjob1472128479229428702.jar tmpDir=null\n",
      "2022-11-15 22:46:46,293 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmaster/172.18.0.5:8032\n",
      "2022-11-15 22:46:46,452 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmaster/172.18.0.5:8032\n",
      "2022-11-15 22:46:46,651 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1668543377787_0007\n",
      "2022-11-15 22:46:47,069 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2022-11-15 22:46:47,163 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2022-11-15 22:46:47,341 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1668543377787_0007\n",
      "2022-11-15 22:46:47,341 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-11-15 22:46:47,501 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-11-15 22:46:47,502 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-11-15 22:46:47,567 INFO impl.YarnClientImpl: Submitted application application_1668543377787_0007\n",
      "2022-11-15 22:46:47,605 INFO mapreduce.Job: The url to track the job: http://yarnmaster:8088/proxy/application_1668543377787_0007/\n",
      "2022-11-15 22:46:47,607 INFO mapreduce.Job: Running job: job_1668543377787_0007\n",
      "2022-11-15 22:46:53,729 INFO mapreduce.Job: Job job_1668543377787_0007 running in uber mode : false\n",
      "2022-11-15 22:46:53,732 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-11-15 22:46:58,836 INFO mapreduce.Job: Task Id : attempt_1668543377787_0007_m_000001_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)\n",
      "\n",
      "2022-11-15 22:46:58,850 INFO mapreduce.Job: Task Id : attempt_1668543377787_0007_m_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)\n",
      "\n",
      "2022-11-15 22:47:03,891 INFO mapreduce.Job: Task Id : attempt_1668543377787_0007_m_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)\n",
      "\n",
      "2022-11-15 22:47:03,893 INFO mapreduce.Job: Task Id : attempt_1668543377787_0007_m_000001_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)\n",
      "\n",
      "2022-11-15 22:47:07,951 INFO mapreduce.Job: Task Id : attempt_1668543377787_0007_m_000001_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)\n",
      "\n",
      "2022-11-15 22:47:07,953 INFO mapreduce.Job: Task Id : attempt_1668543377787_0007_m_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)\n",
      "\n",
      "2022-11-15 22:47:14,009 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-11-15 22:47:14,041 INFO mapreduce.Job: Job job_1668543377787_0007 failed with state FAILED due to: Task failed task_1668543377787_0007_m_000001\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-15 22:47:14,131 INFO mapreduce.Job: Counters: 14\r\n",
      "\tJob Counters \r\n",
      "\t\tFailed map tasks=7\r\n",
      "\t\tKilled map tasks=1\r\n",
      "\t\tKilled reduce tasks=1\r\n",
      "\t\tLaunched map tasks=8\r\n",
      "\t\tOther local map tasks=6\r\n",
      "\t\tData-local map tasks=2\r\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=25284\r\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\r\n",
      "\t\tTotal time spent by all map tasks (ms)=25284\r\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=25284\r\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=25890816\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tCPU time spent (ms)=0\r\n",
      "\t\tPhysical memory (bytes) snapshot=0\r\n",
      "\t\tVirtual memory (bytes) snapshot=0\r\n",
      "2022-11-15 22:47:14,131 ERROR streaming.StreamJob: Job not successful!\r\n",
      "Streaming Command Failed!\r\n"
     ]
    }
   ],
   "source": [
    "!mapred streaming \\\n",
    "  -input /media/notebooks/Modulo1/prueba/texto.txt \\\n",
    "  -output /media/notebooks/Modulo1/prueba/output2 \\\n",
    "  -file ./reducer.py \\\n",
    "  -file ./mapper.py \\\n",
    "  -mapper mapper.py \\\n",
    "  -reducer reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "51d743a874fa8d48e9279318b5d35f29c98b8235464b5f337faba63b3fdbc840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
